### 分析与假设

-   假设，系统  1  个月需要处理  30 M（3000 万）的写请求（长链生成短链服务），那么按照  100 : 1  的读写比例，我们每个月需要处理
    -   URL  跳转的次数为：
        *100 * 30 M = 3B （30*  亿*）\*
    -   每秒需要处理的请求数（QPS）：
        *30 M/ (30 days* 24 hours* 60 min* 60 sec) ≅ 12 requests/second\*
    -   每秒的读请求（短链跳转长链）：
        *100 * 12 requests / second  = 1200 requests/second\*
-   假设我们会默认保存  5  年内的短链转换记录，那么  5  年内产生的  URL  数量：
    _30 M _ 12 _ 5 = 1,800,000,000_
-   假设短链是用 [0-9], [a-z], [A-Z] 这 62 个字符的组合来表示的，那么长度是 N 的短链可以映射的 URL 数量：
    -   62^5 = 916,132,832
    -   62^6 = 56,800,235,584
    -   62^7 = 3,521,614,606,208
        理论上我们的短链设计成 6 个字符就能满足需求了
-   假设数据中的一条记录的平均长度为 500 bytes（每条记录包含长  URL ，短  URL，记录创建时间，过期时间等信息）。那么，
    -   存储空间至少需要：
        _30 M _ 12 * 5 * 500 = 0.9 T\*
    -   入网带宽：
        _12 _ 500 bytes = 6 KB/s = 48 Kbps\*
    -   出网带宽：
        *1200 * 500 bytes = 600 KB/s = 4.8 Mbps\*
-   假设根据  2-8  原则，20%的链接都是活跃链接，我们把每天访问量前  20%  的记录缓存起来，那么需要的内存空间为：
    _100 _ 30 M / 30 * 0.2 * 500 bytes = 10 G\*

### 使用 hash 算法

1. 可以使用么么 hash 算法生成，重复概率小，并且生成效率高
2. 虽然系统前期重复概率小，但是后期还是有重复的可能性的，重复了怎么办。
    1. hash 重复的时候的使用秒级时间戳+生成次数作为种子生成新的链接
    2. 超过 3 次重复提示失败
3. 同一个链接过来怎么办
    1. 需要建立一个映射表，返回缓存或者数据库中的链接
4. 为了运行效率需要做 kv 缓存
    1. 如果每一个链接都设置 kv 的话，内存会消耗过大，这里可以设置一个回收规则
        1. 最近 30 天（按业务来分）内访问的规则不回收
        2. 访问后立即刷新缓存过期时间
5. 短链接过期处理
    1. 为了保持数据一致性先删除数据库再删除缓存
    2. 惰性删除，等待用户访问后再去删除
    3. 主动删除，启用定时脚本删除过期缓存，必须不影响用户正常使用，所以这个脚本频率要低，并且要在用户使用频率低的时间段执行，

### 数据库设计

1. 根据创建时间的 hash 分表，避免单表数据量过大
2. 数据库需要备份
